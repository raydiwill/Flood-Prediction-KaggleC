{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    train_test_split, \n",
    "    cross_val_score,\n",
    "    KFold\n",
    ")\n",
    "from optuna.visualization import (\n",
    "    plot_optimization_history, \n",
    "    plot_param_importances, \n",
    "    plot_slice\n",
    ")\n",
    "from sklearn import set_config\n",
    "#from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.metrics import r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from tqdm import tqdm\n",
    "from openfe import OpenFE, transform, tree_to_formula, ForwardFeatureSelector, TwoStageFeatureSelector\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import shap\n",
    "import warnings\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global configurations for sklearn:\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "# Global configurations for pandas:\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "TRAIN_SIZE = 100000\n",
    "DATA_DIR = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_optimization(train_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" Reduce memory usage of dataframe by modifying type of each column.\n",
    "\n",
    "    Argument:\n",
    "    train_data (pd.DataFrame): The DataFrame to be optimized.\n",
    "    \"\"\"\n",
    "    base_memory = train_data.memory_usage().sum() / 1024**2\n",
    "    print(f'Memory usage of dataframe is {base_memory:.2f} MB')\n",
    "\n",
    "    for column in train_data.columns:\n",
    "        column_type = train_data[column].dtype\n",
    "\n",
    "        if column_type == 'bool':\n",
    "            continue\n",
    "\n",
    "        if column_type != 'category':\n",
    "            column_value_min = train_data[column].min()\n",
    "            column_value_max = train_data[column].max()\n",
    "            if str(column_type)[:3] == 'int':\n",
    "                if column_value_min > np.iinfo(np.int8).min and column_value_max < np.iinfo(np.int8).max:\n",
    "                    train_data[column] = train_data[column].astype(np.int8)\n",
    "                elif column_value_min > np.iinfo(np.int16).min and column_value_max < np.iinfo(np.int16).max:\n",
    "                    train_data[column] = train_data[column].astype(np.int16)\n",
    "                elif column_value_min > np.iinfo(np.int32).min and column_value_max < np.iinfo(np.int32).max:\n",
    "                    train_data[column] = train_data[column].astype(np.int32)\n",
    "                elif column_value_min > np.iinfo(np.int64).min and column_value_max < np.iinfo(np.int64).max:\n",
    "                    train_data[column] = train_data[column].astype(np.int64)  \n",
    "            else:\n",
    "                if column_value_min > np.finfo(np.float16).min and column_value_max < np.finfo(np.float16).max:\n",
    "                    train_data[column] = train_data[column].astype(np.float16)\n",
    "                elif column_value_min > np.finfo(np.float32).min and column_value_max < np.finfo(np.float32).max:\n",
    "                    train_data[column] = train_data[column].astype(np.float32)\n",
    "                else:\n",
    "                    train_data[column] = train_data[column].astype(np.float64)\n",
    "        else:\n",
    "            train_data[column] = train_data[column].astype('category')\n",
    "\n",
    "    optimized_memory = train_data.memory_usage().sum() / 1024**2\n",
    "    optimized_percentage = 100 * (base_memory - optimized_memory) / base_memory\n",
    "\n",
    "    print(f'Memory usage after optimization is: {optimized_memory:.2f} MB')\n",
    "    print(f'Decreased by {optimized_percentage:.1f}%')\n",
    "\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original data\n",
    "org_data = pd.read_csv(DATA_DIR + 'flood.csv')\n",
    "\n",
    "# Competition data\n",
    "org_train = pd.read_csv(DATA_DIR + 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrich dataset\n",
    "org_train.drop('id', axis=1, inplace=True)\n",
    "df = pd.concat([org_train, org_data])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Optimize memory usage\n",
    "df = memory_optimization(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Before concat: {org_train.shape}, {org_data.shape}\\n')\n",
    "print(f'After concat: {df.shape}')\n",
    "\n",
    "del org_train, org_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View columns stats\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null & Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values with a horizontal bar plot\n",
    "df.isnull().sum().plot(kind='barh')\n",
    "plt.title('Missing values per column')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplication\n",
    "print(f'Number of duplicated records: {df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numerical\n",
    "numerical_columns = list(df.select_dtypes(include=['float16', 'int8']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check statistics\n",
    "df[numerical_columns].describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(15, 12))\n",
    "plt.title(\"Numerical features distribution with Histograms\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=df[numerical_columns], orient='h')\n",
    "plt.title('Numerical Features distribution with Boxplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_coefficients = df[numerical_columns].skew()\n",
    "skew_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for inf values\n",
    "for column in df.columns:\n",
    "    if np.isinf(df[column]).any():\n",
    "        print(f\"Column '{column}' contains inf values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_target_df = df.drop('FloodProbability', axis=1)\n",
    "without_target_corr_matrix = no_target_df.corr() # Default is Pearson\n",
    "\n",
    "# Create a mask for the upper triangle\n",
    "mask_up_tri = np.triu(np.ones_like(without_target_corr_matrix, dtype=bool))\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(without_target_corr_matrix.round(3), annot=True, mask=mask_up_tri)\n",
    "plt.title(\"Correlation matrix with Target variable\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix with target\n",
    "df.corr().abs()[\"FloodProbability\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=df, x=\"FloodProbability\")\n",
    "plt.title(\"Flood Probability distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop('FloodProbability', axis=1)\n",
    "target = df[['FloodProbability']]\n",
    "\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=SEED, #shuffle=True\n",
    ")\n",
    "\n",
    "# Check the shape of the train and test data\n",
    "print(f\"Train data shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ofe = OpenFE()\n",
    "\n",
    "# Train on smaller size for faster speed\n",
    "X_ofe = X_train[:200000]\n",
    "y_ofe = y_train[:200000]\n",
    "\n",
    "# Generate new features\n",
    "gen_feats = ofe.fit(data=X_ofe,\n",
    "                    label=y_ofe, \n",
    "                    task='regression', \n",
    "                    metric='rmse',\n",
    "                    feature_boosting=True, \n",
    "                    n_jobs=6, \n",
    "                    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total features generated: {len(ofe.new_features_list)}\\n')\n",
    "\n",
    "# Top 20 features\n",
    "for feature in ofe.new_features_list[:20]:\n",
    "    print(tree_to_formula(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train_sub = X_train[:TRAIN_SIZE]\n",
    "y_train_sub = y_train[:TRAIN_SIZE]\n",
    "\n",
    "X_train_sub, X_test = transform(X_train_sub, X_test, gen_feats, n_jobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fs = ForwardFeatureSelector(task='regression', verbose=False)\n",
    "\n",
    "fs.fit(data=X_train_sub, label=y_train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_testfs = fs.transform(X_train_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric\n",
    "\n",
    "Submissions are evaluated using the R2 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" %%time\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'l2',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'min_data_in_leaf': trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "        #'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'dart']),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'n_jobs': -1,\n",
    "        'random_state': SEED,\n",
    "        'verbosity': -1\n",
    "    }\n",
    "\n",
    "    # Cross-validation setup\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "    r2_scores = []\n",
    "\n",
    "    for train_index, valid_index in kfold.split(X_train, y_train):\n",
    "        train_data = lgb.Dataset(X_train.iloc[train_index], label=y_train.iloc[train_index])\n",
    "        valid_data = lgb.Dataset(X_train.iloc[valid_index], label=y_train.iloc[valid_index])\n",
    "\n",
    "        # Train the model\n",
    "        gbm = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            num_boost_round=100,\n",
    "            valid_sets=[train_data, valid_data],\n",
    "            valid_names=['train', 'valid'],\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=False)]\n",
    "        )\n",
    "\n",
    "        # Predict and calculate R2\n",
    "        y_pred = gbm.predict(X_train.iloc[valid_index], num_iteration=gbm.best_iteration)\n",
    "        r2 = r2_score(y_train.iloc[valid_index], y_pred)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "    return np.mean(r2_scores)\n",
    "\n",
    "\n",
    "study = optuna.create_study(study_name=\"LightGBM\", direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50, n_jobs=-1, show_progress_bar=True)\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "print() \"\"\"\n",
    "\n",
    "\"\"\" LGBM\n",
    "Number of finished trials:  50\n",
    "Best trial:\n",
    "  Value:  0.8448460037468983\n",
    "  Params: \n",
    "    n_estimators: 823\n",
    "    learning_rate: 0.042084691701664546\n",
    "    subsample: 0.8741517323343981\n",
    "    colsample_bytree: 0.5741858210937979\n",
    "    min_data_in_leaf: 22\n",
    "    num_leaves: 39\n",
    "    bagging_freq: 7\n",
    "\n",
    "CPU times: user 1d 11h 23min 55s, sys: 4h 16min 26s, total: 1d 15h 40min 21s\n",
    "Wall time: 6h 57min 11s\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" %%time\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 20),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"n_estimators\": trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'n_jobs': -1,\n",
    "        'random_state': SEED,\n",
    "    }\n",
    "\n",
    "    # Cross-validation setup\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "    r2_scores = []\n",
    "\n",
    "    for train_index, valid_index in kfold.split(X_train, y_train):\n",
    "        # Create DMatrix for training and validation sets with appropriate weights\n",
    "        dtrain = xgb.DMatrix(data=X_train.iloc[train_index], label=y_train.iloc[train_index])\n",
    "        dvalid = xgb.DMatrix(data=X_train.iloc[valid_index], label=y_train.iloc[valid_index])\n",
    "\n",
    "        # Train the model\n",
    "        bst = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=100,\n",
    "            evals=[(dvalid, 'validation')],\n",
    "            early_stopping_rounds=10,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "\n",
    "        # Predict probabilities for the validation set\n",
    "        y_pred = bst.predict(dvalid)\n",
    "\n",
    "        # Calculate R2 and store the score\n",
    "        r2 = r2_score(y_train.iloc[valid_index], y_pred)\n",
    "        r2_scores.append(r2)\n",
    "    \n",
    "    return np.mean(r2_scores)\n",
    "\n",
    "\n",
    "study = optuna.create_study(study_name=\"XGBoost\", direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50, n_jobs=-1, show_progress_bar=True)\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "print() \"\"\"\n",
    "\n",
    "\"\"\" XGBoost\n",
    "{'max_depth': 8,\n",
    " 'min_child_weight': 20,\n",
    " 'subsample': 0.07190228850100583,\n",
    " 'colsample_bytree': 0.5615919991275306,\n",
    " 'learning_rate': 0.09054610792000152,\n",
    " 'n_estimators': 505}\n",
    "\n",
    "Number of finished trials:  50\n",
    "Best trial:\n",
    "  Value:  0.7975471022803855\n",
    "  Params: \n",
    "    max_depth: 8\n",
    "    min_child_weight: 20\n",
    "    subsample: 0.07190228850100583\n",
    "    colsample_bytree: 0.5615919991275306\n",
    "    learning_rate: 0.09054610792000152\n",
    "    n_estimators: 505\n",
    "\n",
    "CPU times: user 2h 11min 31s, sys: 22min 16s, total: 2h 33min 47s\n",
    "Wall time: 35min 13s\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" %%time\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 100, 1000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "        'random_state': SEED,\n",
    "        'loss_function': 'RMSE',\n",
    "        'eval_metric': 'R2',\n",
    "        'early_stopping_rounds': 10,\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    # Cross-validation setup\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "    r2_scores = []\n",
    "\n",
    "    for train_index, valid_index in kfold.split(X_train, y_train):\n",
    "        X_train_split, X_valid_split = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "        y_train_split, y_valid_split = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "\n",
    "        model = CatBoostRegressor(**params)\n",
    "        model.fit(X_train_split, y_train_split,\n",
    "                  eval_set=(X_valid_split, y_valid_split),\n",
    "                  use_best_model=True)\n",
    "\n",
    "        # Predict probabilities for the validation set\n",
    "        y_pred = model.predict(X_valid_split)\n",
    "\n",
    "        # Calculate R2 and store the score\n",
    "        r2 = r2_score(y_valid_split, y_pred)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "    return np.mean(r2_scores)\n",
    "\n",
    "\n",
    "study = optuna.create_study(study_name=\"CatBoost\", direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "print() \"\"\"\n",
    "\n",
    "\"\"\" CatBoost\n",
    "{'iterations': 991,\n",
    " 'learning_rate': 0.09877620412322519,\n",
    " 'depth': 5,\n",
    " 'subsample': 0.9609189454297099,\n",
    " 'colsample_bylevel': 0.8196165977934415,\n",
    " 'min_data_in_leaf': 81}\n",
    "\n",
    "Number of finished trials:  50\n",
    "Best trial:\n",
    "  Value:  0.8497594589181798\n",
    "  Params: \n",
    "    iterations: 991\n",
    "    learning_rate: 0.09877620412322519\n",
    "    depth: 5\n",
    "    subsample: 0.9609189454297099\n",
    "    colsample_bylevel: 0.8196165977934415\n",
    "    min_data_in_leaf: 81\n",
    "\n",
    "CPU times: user 15h 56min 41s, sys: 43min 58s, total: 16h 40min 39s\n",
    "Wall time: 4h 14min 36s\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(\n",
    "    max_depth=8,\n",
    "    min_child_weight=20,\n",
    "    subsample=0.07190228850100583,\n",
    "    colsample_bytree=0.5615919991275306,\n",
    "    learning_rate=0.09054610792000152,\n",
    "    n_estimators=505,\n",
    "    objective='reg:squarederror',\n",
    "    # eval_metric='auc',\n",
    "    # tree_method='gpu_hist',  # Uncomment if using GPU\n",
    "    # random_state=SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgbm = LGBMRegressor(\n",
    "    n_estimators=823,\n",
    "    learning_rate=0.042084691701664546,\n",
    "    subsample=0.8741517323343981,\n",
    "    colsample_bytree=0.5741858210937979,\n",
    "    min_data_in_leaf=22,\n",
    "    boosting_type='gbdt',\n",
    "    num_leaves=39,\n",
    "    bagging_freq=7,\n",
    "    objective='regression',\n",
    "    metric='l2',\n",
    "    # device_type='gpu', \n",
    "    # random_state=SEED,\n",
    "    verbosity=-1,\n",
    "    num_threads=-1\n",
    ")\n",
    "\n",
    "cat = CatBoostRegressor(\n",
    "    iterations=991,\n",
    "    learning_rate=0.09877620412322519,\n",
    "    depth=5,\n",
    "    subsample=0.9609189454297099,\n",
    "    colsample_bylevel=0.8196165977934415,\n",
    "    min_data_in_leaf=81,\n",
    "    random_state=SEED,\n",
    "    loss_function='RMSE',\n",
    "    eval_metric='R2',\n",
    "    early_stopping_rounds=10,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Cross-validation split\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "\n",
    "xgb_scores = cross_val_score(xgb, X_train, y_train, cv=kfold, scoring='r2', n_jobs=-1)\n",
    "lgbm_scores = cross_val_score(lgbm, X_train, y_train, cv=kfold, scoring='r2', n_jobs=-1)\n",
    "cat_scores = cross_val_score(cat, X_train, y_train, cv=kfold, scoring='r2', n_jobs=-1)\n",
    "\n",
    "cv_scores = [xgb_scores, lgbm_scores, cat_scores]\n",
    "\n",
    "r2_df = pd.DataFrame(\n",
    "    {\n",
    "        'Model': ['XGBoost', 'LightGBM', 'CatBoost'],\n",
    "        'Mean R2': np.mean(cv_scores, axis=1)\n",
    "    }\n",
    ")\n",
    "r2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenFE features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Cross-validation setup\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "\n",
    "r2_scores = []\n",
    "for train_index, valid_index in tqdm(kfold.split(X_train_sub, y_train_sub), total=kfold.get_n_splits(), desc='K-Fold Progress'):\n",
    "    train_data = lgb.Dataset(X_train_sub.iloc[train_index], label=y_train_sub.iloc[train_index])\n",
    "    valid_data = lgb.Dataset(X_train_sub.iloc[valid_index], label=y_train_sub.iloc[valid_index])\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': 823,\n",
    "        'learning_rate': 0.042084691701664546,\n",
    "        'subsample': 0.8741517323343981,\n",
    "        'colsample_bytree': 0.5741858210937979,\n",
    "        'min_data_in_leaf': 22,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 39,\n",
    "        'bagging_freq': 7,\n",
    "        'objective': 'regression',\n",
    "        'metric': 'l2',\n",
    "        #'device_type': 'gpu',  \n",
    "        'random_state': SEED,  \n",
    "        'verbosity': -1,\n",
    "        'num_threads': -1  # Use all available threads\n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    gbm = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=100,\n",
    "        valid_sets=[train_data, valid_data],\n",
    "        valid_names=['train', 'valid'],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=False)]\n",
    "    )\n",
    "\n",
    "    # Predict and calculate R2\n",
    "    y_pred = gbm.predict(X_train_sub.iloc[valid_index], num_iteration=gbm.best_iteration)\n",
    "    r2 = r2_score(y_train_sub.iloc[valid_index], y_pred)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "print(f'Mean R2: {np.mean(r2_scores):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Cross-validation setup\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "\n",
    "r2_scores = []\n",
    "for train_index, valid_index in tqdm(kfold.split(X_train_sub, y_train_sub), total=kfold.get_n_splits(), desc='K-Fold Progress'):\n",
    "    # Create DMatrix for training and validation sets with appropriate weights\n",
    "    dtrain = xgb.DMatrix(data=X_train_sub.iloc[train_index], label=y_train_sub.iloc[train_index], enable_categorical=True)\n",
    "    dvalid = xgb.DMatrix(data=X_train_sub.iloc[valid_index], label=y_train_sub.iloc[valid_index], enable_categorical=True)\n",
    "\n",
    "    params = {\n",
    "        'max_depth': 8,\n",
    "        'min_child_weight': 20,\n",
    "        'subsample': 0.07190228850100583,\n",
    "        'colsample_bytree': 0.5615919991275306,\n",
    "        'learning_rate': 0.09054610792000152,\n",
    "        'n_estimators': 505,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'random_state': SEED,  \n",
    "        'n_jobs': -1,  # Use all available threads\n",
    "        'enable_categorical': True\n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    bst = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=100,\n",
    "        evals=[(dvalid, 'validation')],\n",
    "        early_stopping_rounds=10,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    # Predict probabilities for the validation set\n",
    "    y_pred = bst.predict(dvalid)\n",
    "\n",
    "    # Calculate R2 and store the score\n",
    "    r2 = r2_score(y_train_sub.iloc[valid_index], y_pred)\n",
    "    r2_scores.append(r2)\n",
    "    \n",
    "print(f'Mean R2: {np.mean(r2_scores):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "categorical_features = X_train_sub.select_dtypes(include=['category']).columns.tolist()\n",
    "for column in categorical_features:\n",
    "    X_train_sub[column] = X_train_sub[column].astype(str)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "\n",
    "r2_scores = []\n",
    "for train_index, valid_index in tqdm(kfold.split(X_train_sub, y_train_sub), total=kfold.get_n_splits(), desc='K-Fold Progress'):\n",
    "    X_train_split, X_valid_split = X_train_sub.iloc[train_index], X_train_sub.iloc[valid_index]\n",
    "    y_train_split, y_valid_split = y_train_sub.iloc[train_index], y_train_sub.iloc[valid_index]\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "            iterations=991,\n",
    "            learning_rate=0.09877620412322519,\n",
    "            depth=5,\n",
    "            subsample=0.9609189454297099,\n",
    "            colsample_bylevel=0.8196165977934415,\n",
    "            min_data_in_leaf=81,\n",
    "            random_state=SEED,\n",
    "            loss_function='RMSE',\n",
    "            eval_metric='R2',\n",
    "            early_stopping_rounds=10,\n",
    "            verbose=False,\n",
    "            cat_features=categorical_features\n",
    "        )\n",
    "    model.fit(X_train_split, y_train_split,\n",
    "                eval_set=(X_valid_split, y_valid_split),\n",
    "                use_best_model=True)\n",
    "\n",
    "    # Predict probabilities for the validation set\n",
    "    y_pred = model.predict(X_valid_split)\n",
    "\n",
    "    # Calculate R2 and store the score\n",
    "    r2 = r2_score(y_valid_split, y_pred)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "print(f'Mean R2: {np.mean(r2_scores):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.fit(X_train, y_train)\n",
    "y_pred_cat = cat.predict(X_test)\n",
    "r2_cat = r2_score(y_test, y_pred_cat)\n",
    "print(f'CatBoost R2: {r2_cat}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = X_train_testfs.select_dtypes(include=['category']).columns.tolist()\n",
    "for column in categorical_features:\n",
    "    X_train_testfs[column] = X_train_testfs[column].astype(str)\n",
    "\n",
    "best_model = CatBoostRegressor(\n",
    "            iterations=991,\n",
    "            learning_rate=0.09877620412322519,\n",
    "            depth=5,\n",
    "            subsample=0.9609189454297099,\n",
    "            colsample_bylevel=0.8196165977934415,\n",
    "            min_data_in_leaf=81,\n",
    "            random_state=SEED,\n",
    "            loss_function='RMSE',\n",
    "            eval_metric='R2',\n",
    "            early_stopping_rounds=10,\n",
    "            verbose=False,\n",
    "            cat_features=categorical_features\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_train_testfs, y_train_sub)\n",
    "\n",
    "X_test = fs.transform(X_test)\n",
    "for column in categorical_features:\n",
    "    X_test[column] = X_test[column].astype(str)\n",
    "    \n",
    "y_pred_cat = best_model.predict(X_test)\n",
    "r2_cat = r2_score(y_test, y_pred_cat)\n",
    "print(f'CatBoost R2: {r2_cat}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction & Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain before prediction\n",
    "cat.fit(features, target)\n",
    "\n",
    "# Predict the target variable\n",
    "test = pd.read_csv(DATA_DIR + 'test.csv')\n",
    "predictions = cat.predict(test.drop('id', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_df = pd.DataFrame()\n",
    "test = pd.read_csv(DATA_DIR + 'test.csv')\n",
    "test.drop('id', axis=1, inplace=True)\n",
    "test, test_df = transform(test, test_df, new_features_list=gen_feats, n_jobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = fs.transform(test)\n",
    "predictions = best_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')\n",
    "sub['FloodProbability'] = predictions\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 0.85831 \n",
    "label = \"FloodProbability\"\n",
    "predictor = TabularPredictor(label=label).fit(df)\n",
    "\n",
    "test = pd.read_csv(DATA_DIR + 'test.csv')\n",
    "predictions = predictor.predict(test.drop('id', axis=1))\n",
    "\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')\n",
    "sub[label] = predictions\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
